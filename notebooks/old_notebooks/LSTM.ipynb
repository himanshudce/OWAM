{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T10:13:44.950429Z",
     "start_time": "2021-02-19T10:13:39.646691Z"
    },
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import time\n",
    "import pickle\n",
    "pd.set_option('display.max_rows', 500)\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "\n",
    "# define random seeds for Neural Networks\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "# ignore warnings jupyter notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBIS FRAMEWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../results/OBIS_results.pickle', 'rb') as f:\n",
    "    results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T14:03:27.527623Z",
     "start_time": "2021-02-19T14:03:27.520877Z"
    }
   },
   "outputs": [],
   "source": [
    "#used functions:\n",
    "\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = pd.DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = pd.concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    "\n",
    "\n",
    "def init_model(train_X):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    model.compile(loss=keras.losses.MeanSquaredLogarithmicError(), optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def train_model(train_X,train_y,test_X,test_y,model):\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "    history = model.fit(train_X, train_y, epochs=250, batch_size=64, validation_data=(test_X, test_y), \n",
    "                        verbose=0,callbacks=[es], shuffle=False)\n",
    "\n",
    "    return history, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T15:20:51.004655Z",
     "start_time": "2021-02-19T15:19:19.764113Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_intersections={\"T1\":{\"North\":\"K504\", \"South\":\"K198\"},\n",
    "                      \"T2\":{\"North\":\"K703\", \"South\":\"K206\"}}\n",
    "thresholds = [1,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0]\n",
    "def build_LSTMs(results,targets=target_intersections,thesholds=thresholds):\n",
    "    \"\"\"Takes the entire results dict and builds LSTM models for each trajectory and direction\"\"\"\n",
    "    errors={}\n",
    "    dfs={}\n",
    "    intersection_arrays = []\n",
    "    for trajectory in results.keys():\n",
    "        errors[trajectory]={}\n",
    "        print(\"Starting trajectory: {}\".format(trajectory))\n",
    "        for direction in results[trajectory]:\n",
    "            errors[trajectory][direction]={}\n",
    "            print(\"Starting direction: {}\".format(direction))\n",
    "            lof = results[trajectory][direction]['lof_df'] # load LOF DF for cors\n",
    "            data = pd.DataFrame()\n",
    "            for intersection_name in results[trajectory][direction]['raw']:\n",
    "                intersection = results[trajectory][direction]['raw'][intersection_name]\n",
    "                intersection = intersection.rename(columns={\"cars\": intersection_name})\n",
    "                intersection = intersection.set_index(pd.DatetimeIndex(intersection['timestamp']))\n",
    "                intersection = intersection.drop(columns=['timestamp'])\n",
    "                data = pd.merge(data, intersection, left_index=True, right_index=True, how='outer')\n",
    "            data.dropna(inplace=True)\n",
    "            dfs[\"{}_{}\".format(trajectory,direction)] = data\n",
    "\n",
    "            for threshold in thresholds:\n",
    "                errors[trajectory][direction][threshold] ={}\n",
    "                print(\"Threshold: {}\".format(threshold))\n",
    "                #grab relevant intersections:\n",
    "                target = target_intersections[trajectory][direction]\n",
    "                isct_inc = lof.corr()[lof.corr()[target]>=threshold].index.tolist()\n",
    "                if (isct_inc in intersection_arrays) & (threshold != 0.4):\n",
    "                    print(\"same intersections, copy MSE\")\n",
    "                    errors[trajectory][direction][threshold]['MSE'] = mse(preds,val_y)\n",
    "                else:    \n",
    "                    print(\"Intersections included: {}\".format(len(isct_inc)))\n",
    "                    errors[trajectory][direction][threshold]['intersections'] = isct_inc\n",
    "\n",
    "                    df = data[isct_inc].copy(deep=True)\n",
    "\n",
    "                    #move target var to front of DF\n",
    "                    df = df[ [target] + [ col for col in df.columns if col != target ] ]\n",
    "\n",
    "                    #do scaling:\n",
    "                    scaler = StandardScaler()\n",
    "                    df= scaler.fit_transform(df.values)\n",
    "                    df_test = df[math.ceil(len(df)*0.8):]\n",
    "                    df = df[:math.ceil(len(df)*0.8)]\n",
    "\n",
    "                    # specify the lag sequence\n",
    "                    sequence_length = 12\n",
    "                    n_features = len(isct_inc)\n",
    "                    # frame as supervised learning\n",
    "                    reframed = series_to_supervised(df, sequence_length, 1)\n",
    "                    # print(reframed)\n",
    "                    # split into train and test sets\n",
    "                    values = reframed.values\n",
    "                    n_train_hours = math.ceil(len(df)*0.8)\n",
    "                    train = values[:n_train_hours, :]\n",
    "                    test = values[n_train_hours:, :]\n",
    "                    # split into input and outputs\n",
    "                    n_obs = sequence_length * n_features\n",
    "                    train_X, train_y = train[:, :n_obs], train[:, -n_features]\n",
    "                    test_X, test_y = test[:, :n_obs], test[:, -n_features]\n",
    "                    # reshape input to be 3D [samples, timesteps, features]\n",
    "                    train_X = train_X.reshape((train_X.shape[0], sequence_length, n_features))\n",
    "                    test_X = test_X.reshape((test_X.shape[0], sequence_length, n_features))\n",
    "                    #init model & train stuff\n",
    "                    model=init_model(train_X)\n",
    "                    history,model = train_model(train_X,train_y,test_X,test_y,model)\n",
    "\n",
    "                    #eval:\n",
    "                    reframed = series_to_supervised(df_test, sequence_length, 1)\n",
    "                    values = reframed.values\n",
    "                    train = values\n",
    "                    n_obs = sequence_length * n_features\n",
    "                    val_X, val_y = train[:, :n_obs], train[:, -n_features]\n",
    "                    val_X = val_X.reshape((val_X.shape[0], sequence_length, n_features))\n",
    "                    preds = model.predict(val_X)\n",
    "                    preds =preds.reshape(len(df_test)-sequence_length)\n",
    "\n",
    "                    model=init_model(train_X)\n",
    "                    history,model = train_model(train_X,train_y,test_X,test_y,model)\n",
    "\n",
    "                    #eval:\n",
    "                    reframed = series_to_supervised(df_test, sequence_length, 1)\n",
    "                    values = reframed.values\n",
    "                    train = values\n",
    "                    n_obs = sequence_length * n_features\n",
    "                    val_X, val_y = train[:, :n_obs], train[:, -n_features]\n",
    "                    val_X = val_X.reshape((val_X.shape[0], sequence_length, n_features))\n",
    "                    preds = model.predict(val_X)\n",
    "                    preds =preds.reshape(len(df_test)-sequence_length)\n",
    "\n",
    "\n",
    "                    errors[trajectory][direction][threshold]['df'] = pd.DataFrame({\"Real\":val_y,\"Predicted\":preds,'SE':(val_y-preds)**2})\n",
    "                    errors[trajectory][direction][threshold]['MSE'] = mse(preds,val_y)\n",
    "                #save model\n",
    "                \n",
    "                path= '.\\\\{}\\\\{}\\\\{}\\\\'.format(trajectory,direction,threshold)\n",
    "                if not os.path.exists(path):\n",
    "                    os.makedirs(path)\n",
    "                model.save(path+\"model\")\n",
    "                \n",
    "                print(mse(preds,val_y))\n",
    "                intersection_arrays.append(isct_inc)\n",
    "\n",
    "    return errors,dfs #errors\n",
    "lstm, data = build_LSTMs(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('LSTM_results_april.pickle', 'wb') as file:\n",
    "    pickle.dump([lstm,data],file)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(errors):\n",
    "    df = pd.DataFrame()\n",
    "    row = {}\n",
    "    for trajectory in errors.keys():\n",
    "        for direction in errors[trajectory].keys():\n",
    "            row['model']=\"T{}_{}\".format(trajectory,direction[0])\n",
    "            for threshold in errors[trajectory][direction].keys():\n",
    "                row[\"T{}\".format(threshold)] = round(errors[trajectory][direction][threshold]['MSE'],3)\n",
    "            df = df.append(row,ignore_index=True)\n",
    "    return df\n",
    "plotting_results = plot_results(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_results.append(test.describe().iloc[1]) #add means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_results.append(plotting_results.describe().iloc[1]) #add means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_mse_calc(lstm=lstm,data=data,results=results,outliers=5,target_intersections=target_intersections):\n",
    "    \"\"\"calculates MSE per model for top 'outliers' in test set\"\"\"\n",
    "    mse_results=pd.DataFrame(columns=['Model','T 1.0','T 0.4','T 0.0'])\n",
    "    thresholds = [1,0.4]\n",
    "    for trajectory in ['T1','T2']:\n",
    "        for direction in results[trajectory].keys():\n",
    "            mses=[]\n",
    "            for threshold in thresholds:\n",
    "                #get preds, rawdata & lof dfs:\n",
    "                print(trajectory,direction,threshold)\n",
    "                preds = lstm[trajectory][direction][threshold]['df'].copy(deep=True)\n",
    "                rawdata = data['{}_{}'.format(trajectory, direction)].iloc[-len(preds):].copy(deep=True)\n",
    "                lof = results[trajectory][direction]['lof_df'].copy(deep=True)\n",
    "                #take LOF df:\n",
    "                lof = lof[lof.index> rawdata.iloc[0].name]\n",
    "                \n",
    "                #sort LOF df on outliers & take top 5 outliers for target intersection:\n",
    "                lof.sort_values(by=target_intersections[trajectory][direction], ascending=False, inplace=True)\n",
    "                outliers = lof.iloc[:5].index\n",
    "                \n",
    "                #insert dates on lstm preds df:\n",
    "                preds['Time'] = rawdata.index\n",
    "                outlier_df= pd.DataFrame()\n",
    "\n",
    "                for outlier in outliers:\n",
    "                    one_outlier = preds[(preds['Time']>=outlier) & (preds['Time']<(outlier+pd.Timedelta('1H')))]\n",
    "                    outlier_df = pd.concat([outlier_df,one_outlier])\n",
    "                mses.append(round(outlier_df['SE'].mean(),3))\n",
    "            mse_results = mse_results.append({'Model':\"{}_{}\".format(trajectory,direction),\n",
    "                                'T 1.0':mses[0],'T 0.4':mses[1]},ignore_index=True)\n",
    "    return mse_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm['T1']['North'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_results = outlier_mse_calc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mse_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_results = mse_results.append({'Model':'Mean','T 1.0':round(mse_results.describe().iloc[1]['T 1.0'],3),\n",
    "                                  \"T 0.4\":round(mse_results.describe().iloc[1]['T 0.4'],3)},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save all extra stuff:\n",
    "all_stuff = [lstm,data,results]\n",
    "with open('march30_save.pickle', 'wb') as f:\n",
    "    pickle.dump(all_stuff,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "obis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "fa6dfa9234ed867468e6ff6815fdf65ac16cecec13664949e7beba0e616085c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
